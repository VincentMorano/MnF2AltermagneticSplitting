{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importing libraries and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import IPython\n",
    "    shell = IPython.get_ipython()\n",
    "    shell.enable_matplotlib(gui='qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from MJOLNIR import _tools\n",
    "from MJOLNIR.Data import DataSet\n",
    "from lmfit import Model, Parameter, report_fit\n",
    "from MJOLNIR.Data import Mask\n",
    "from MJOLNIR._tools import fileListGenerator\n",
    "\n",
    "import numpy as np\n",
    "from os import path\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian(x,A,mu,sigma,B):\n",
    "    return A*np.exp(-np.power(x-mu,2.0)/(2.0*sigma**2))+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(ds,treshold):\n",
    "    i=0\n",
    "    for dataset in range(len(ds)):\n",
    "        for a3 in range(0,len(ds.a3[dataset])-1):\n",
    "            if (np.sum(ds[dataset].I[a3,:,:],axis=(0,1))<treshold):\n",
    "                ds[dataset].I[a3,:,:]=0\n",
    "                ds[dataset].Monitor[a3,:,:]=0\n",
    "                i=i+1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example how to load and convert files. Choose binning 1-8. Use binning 8 for high resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in dataset if you want to rotate by angle alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (not used) AZ fitting: 1.5 K, 0 T, High E-resolution scan, (HHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2644-2659\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "dsHR = DataSet.DataSet(files)\n",
    "dsHR.convertDataFile(binning = 8,saveFile=False) \n",
    "\n",
    "# Mask tube 23 which is displaced in the older normalization\n",
    "mask=[]\n",
    "mask.append(Mask.indexMask(23,24,axis=1))\n",
    "dsHR.mask = [np.logical_or(m1,m2) for m1,m2 in zip(dsHR.mask,np.sum(mask)(dsHR))]\n",
    "\n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(dsHR,treshold)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Global fitting: 1.6 K, 0 T, Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (HHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2588-2608\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "dsHHL = DataSet.DataSet(files)\n",
    "dsHHL.convertDataFile(binning = 8,saveFile=False) \n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(dsHHL,treshold)\n",
    "print(i)\n",
    "\n",
    "# Symmetrize\n",
    "for i,df in enumerate(dsHHL):\n",
    "    H,K,L = df.h,df.k,df.l\n",
    "    df.qx,df.qy = df.sample.calculateHKLToQxQy(np.abs(H),np.abs(K),np.abs(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (H0L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"1371-1388\",r\"U:\\Data\\CAMEA\\MnF2\\hdfH0L\",2021)\n",
    "dsH0L = DataSet.DataSet(files)\n",
    "dsH0L.convertDataFile(binning = 8,saveFile=False) \n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(dsH0L,treshold)\n",
    "print(i)\n",
    "\n",
    "# Symmetrize\n",
    "for i,df in enumerate(dsH0L):\n",
    "    H,K,L = df.h,df.k,df.l\n",
    "    df.qx,df.qy = df.sample.calculateHKLToQxQy(np.abs(H),np.abs(K),np.abs(L)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (HK0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2745-2767\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "dsHK0 = DataSet.DataSet(files)\n",
    "dsHK0.convertDataFile(binning = 8,saveFile=False) \n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(dsHK0,treshold)\n",
    "print(i)\n",
    "\n",
    "# Symmetrize\n",
    "for i,df in enumerate(dsHK0):\n",
    "    H,K,L = df.h,df.k,df.l\n",
    "    df.qx,df.qy = df.sample.calculateHKLToQxQy(np.abs(H),np.abs(K),np.abs(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Update lattice parameters to restore expected symmetry of the dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsHHL.updateSampleParameters([dsHHL[0].sample.a,dsHHL[0].sample.b,1.002*dsHHL[0].sample.c,dsHHL[0].sample.alpha,dsHHL[0].sample.beta,dsHHL[0].sample.gamma])\n",
    "dsH0L.updateSampleParameters([0.992*dsH0L[0].sample.a,0.992*dsH0L[0].sample.b,0.987*dsH0L[0].sample.c,dsH0L[0].sample.alpha,dsH0L[0].sample.beta,dsH0L[0].sample.gamma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Other Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.5 K, 10 T, Global scan, (HHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2671-2694\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "ds10T = DataSet.DataSet(files)\n",
    "ds10T.convertDataFile(binning = 8,saveFile=False) \n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(ds10T,treshold)\n",
    "print(i)\n",
    "\n",
    "# Symmetrize\n",
    "for i,df in enumerate(ds10T):\n",
    "    H,K,L = df.h,df.k,df.l\n",
    "    df.qx,df.qy = df.sample.calculateHKLToQxQy(np.abs(H),np.abs(K),np.abs(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.5 K, 10 T, ZFC, High E-resolution scan, (HHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2695-2710\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "ds2 = DataSet.DataSet(files)\n",
    "ds2.convertDataFile(binning = 8,saveFile=False) \n",
    "\n",
    "# Mask tube 23 which is displaced in the older normalization\n",
    "mask=[]\n",
    "mask.append(Mask.indexMask(23,24,axis=1))\n",
    "ds2.mask = [np.logical_or(m1,m2) for m1,m2 in zip(ds2.mask,np.sum(mask)(ds2))]\n",
    "\n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(ds2,treshold)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.5 K, 10 T, FC, High E-resolution scan, (HHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2711-2718\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "ds = DataSet.DataSet(files)\n",
    "ds.convertDataFile(binning = 8,saveFile=False) \n",
    "\n",
    "# Mask tube 23 which is displaced in the older normalization\n",
    "mask=[]\n",
    "mask.append(Mask.indexMask(23,24,axis=1))\n",
    "ds.mask = [np.logical_or(m1,m2) for m1,m2 in zip(ds.mask,np.sum(mask)(ds))]\n",
    "\n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(ds,treshold)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.5 K, 8 T, ZFC, (HK0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = _tools.fileListGenerator(\"2783-2799\",r\"U:\\Data\\CAMEA\\MnF2\\hdf\",2024)\n",
    "ds = DataSet.DataSet(files)\n",
    "ds.convertDataFile(binning = 8,saveFile=False) \n",
    "#check if problems are in some dataset and correct for it:\n",
    "treshold=50\n",
    "i=cleaning(ds,treshold)\n",
    "print(i)\n",
    "\n",
    "# Symmetrize\n",
    "for i,df in enumerate(ds):\n",
    "    H,K,L = df.h,df.k,df.l\n",
    "    df.qx,df.qy = df.sample.calculateHKLToQxQy(np.abs(H),np.abs(K),np.abs(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# (not used) Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case some data should be masked out (needs modification for your sample) (adapt accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=[]\n",
    "ds=ds\n",
    "#Mask for Currate Axes spurions (Q points in [] and width given in dqx, dqy)\n",
    "mask.append(Mask.CurratAxeMask([[1,1,0],[-1,-1,0],[1,0,0]],dqx=0.07,dqy=0.07))\n",
    "\n",
    "ds.mask = [np.logical_or(m1,m2) for m1,m2 in zip(ds.mask,np.sum(mask)(ds))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3D view of dataset\n",
    "\n",
    "Binning along Qx, Qy, energy. Qx nd Qx = 0.02 are good if 1 degree steps in a3 are used, energy 0.1-0.2 is reasonable for overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "Viewer = dsHHL.View3D(0.03,0.03,.05,grid=9,rlu=True)\n",
    "Viewer.caxis=(-0.0,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Perform Cuts and Combine Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (not used) 1.5 K, 0 T, A to Z for J3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFramesAZ = [] # Holder for data\n",
    "\n",
    "QEListAZ = np.array([[0.5,0.5,0.5,6.4,7.5],\n",
    "                [0.55,0.55,0.5,6.4,7.5],\n",
    "                [0.6,0.6,0.5,6.4,7.5],\n",
    "                [0.65,0.65,0.5,6.4,7.5],\n",
    "                [0.7,0.7,0.5,6.4,7.5],\n",
    "                [0.75,0.75,0.5,6.4,7.5],\n",
    "                [0.8,0.8,0.5,6.4,7.5],\n",
    "                [0.85,0.85,0.5,6.4,7.5],\n",
    "                [0.9,0.9,0.5,6.4,7.5],\n",
    "                [0.95,0.95,0.5,6.4,7.5],\n",
    "                [1,1,0.5,6.4,7.5]])\n",
    "\n",
    "widthAZ = 0.05 # 1/Å\n",
    "minPixelAZ = 0.025 # meV\n",
    "\n",
    "for QPoint in QEListAZ:\n",
    "    dat,_ = dsHR.cut1DE(q=QPoint[0:3],E1=QPoint[3],E2=QPoint[4],width=widthAZ,minPixel=minPixelAZ,constantBins=True)\n",
    "    dataFramesAZ.append(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.5 K, 0 T, Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrames = [] # Holder for data\n",
    "\n",
    "QEListHHL = np.array([[0,0,0.8,0.7,7.5],\n",
    "                [0,0,0.85,0.7,7.5],\n",
    "                [0,0,0.9,0.7,7.5],\n",
    "                [0,0,0.95,0.7,7.5],\n",
    "                [0,0,1,0.7,3.0],\n",
    "                [0.5,0.5,0,5,6.8],\n",
    "                [0.5,0.5,0.05,5,6.8],\n",
    "                [0.5,0.5,0.1,5,6.9],\n",
    "                [0.5,0.5,0.15,5,7.05],\n",
    "                [0.5,0.5,0.2,5,7.2],\n",
    "                [0.5,0.5,0.25,5,7.35],\n",
    "                [0.5,0.5,0.3,5,7.5],\n",
    "                [0.5,0.5,0.35,5,7.25],\n",
    "                [0.5,0.5,0.4,5,7.5],\n",
    "                [0.5,0.5,0.45,5,7.5],\n",
    "                [0.5,0.5,0.5,5,7.5],\n",
    "                [0.5,0.5,0.55,5,7.5],\n",
    "                [0.5,0.5,0.6,5,7.5],\n",
    "                [0.5,0.5,0.65,5,7.5],\n",
    "                [0.5,0.5,0.7,5,7.5],\n",
    "                [0.5,0.5,0.75,5,7.5],\n",
    "                [0.5,0.5,0.8,5,7.5],\n",
    "                [0.5,0.5,0.85,5,7.5],\n",
    "                [0.5,0.5,0.9,5,7.5],\n",
    "                [0.5,0.5,0.95,5,7.5],\n",
    "                [0.5,0.5,1,5,7.5],\n",
    "                [1,1,0.1,0.7,7.5],\n",
    "                [1,1,0.15,0.7,7.5],\n",
    "                [1,1,0.2,0.7,7.5],\n",
    "                [1,1,0.25,0.7,7.5],\n",
    "                [1,1,0.3,0.7,7.5],\n",
    "                [1,1,0.35,0.7,7.5],\n",
    "                [1,1,0.4,0.7,7.5],\n",
    "                [1,1,0.45,0.7,7.5],\n",
    "                [1,1,0.5,0.7,7.5],\n",
    "                [1,1,0.55,0.7,7.5],\n",
    "                [1,1,0.6,2.5,7.5],\n",
    "                [1,1,0.65,2.5,7.5],\n",
    "                [1,1,0.7,2.5,7.5],\n",
    "                [1,1,0.75,2.5,7.5],\n",
    "                [0.15,0.15,0.5,5,7.2],\n",
    "                [0.2,0.2,0.5,5,7.5],\n",
    "                [0.25,0.25,0.5,5,7.5],\n",
    "                [0.3,0.3,0.5,5,7.5],\n",
    "                [0.35,0.35,0.5,5,7.5],\n",
    "                [0.4,0.4,0.5,5,7.5],\n",
    "                [0.45,0.45,0.5,5,7.5],\n",
    "#                [0.5,0.5,0.5,0.7,7.5],\n",
    "                [0.55,0.55,0.5,0.7,7.5],\n",
    "                [0.6,0.6,0.5,0.7,7.5],\n",
    "                [0.65,0.65,0.5,0.7,7.5],\n",
    "                [0.7,0.7,0.5,0.7,7.5],\n",
    "                [0.75,0.75,0.5,0.7,7.5],\n",
    "                [0.8,0.8,0.5,0.7,7.5],\n",
    "                [0.85,0.85,0.5,0.7,7.5],\n",
    "                [0.9,0.9,0.5,0.7,7.5],\n",
    "                [0.95,0.95,0.5,0.7,7.5],\n",
    "#                [1,1,0.5,0.7,7.5],\n",
    "                [0.05,0.05,1,0.7,7.5],\n",
    "                [0.1,0.1,1,0.7,7.5],\n",
    "                [0.15,0.15,1,0.7,7.5],\n",
    "                [0.2,0.2,1,0.7,7.5],\n",
    "                [0.25,0.25,1,0.7,7.5],\n",
    "                [0.3,0.3,1,0.7,7.5],\n",
    "                [0.35,0.35,1,0.7,7.5],\n",
    "                [0.4,0.4,1,0.7,7.5],\n",
    "                [0.45,0.45,1,0.7,7.5],\n",
    "#                [0.5,0.5,1,0.7,7.5],\n",
    "                [0.55,0.55,1,0.7,7.5],\n",
    "                [0.6,0.6,1,0.7,7.5],\n",
    "                ])\n",
    "\n",
    "QEListH0L = np.array([[0.7,0,0,0.7,6],\n",
    "                [0.75,0,0,0.7,6],\n",
    "                [0.8,0,0,0.7,6.5],\n",
    "                [0.85,0,0,0.7,7],\n",
    "                [0.9,0,0,0.9,5],\n",
    "                [0.95,0,0,0.6,4],\n",
    "                [1,0,0,0.6,4],\n",
    "                [1.05,0,0,0.6,4],\n",
    "                [1.1,0,0,0.9,5],\n",
    "                [1.15,0,0,1.8,7],\n",
    "                [1.2,0,0,2.7,7],\n",
    "                [1.25,0,0,2.7,7],\n",
    "                [1.3,0,0,2.7,7],\n",
    "                [1.35,0,0,2.7,7],\n",
    "                [1.4,0,0,2.7,7],\n",
    "                [1.45,0,0,3.5,7],\n",
    "                [1.5,0,0,3.5,7],\n",
    "                [0.7,0,0.5,5,7.4],\n",
    "                [0.75,0,0.5,5,7.4],\n",
    "                [0.8,0,0.5,5,7.4],\n",
    "                [0.85,0,0.5,5,7.4],\n",
    "                [0.9,0,0.5,5,7.4],\n",
    "                [0.95,0,0.5,5,7.4],\n",
    "                [1,0,0.5,5,7.4],\n",
    "                [1.05,0,0.5,5,7.4],\n",
    "                [1.1,0,0.5,5,7.4],\n",
    "                [1.15,0,0.5,5,7.4],\n",
    "                [1.2,0,0.5,5,7.4],\n",
    "                [1.25,0,0.5,5,7.4],\n",
    "                [1.3,0,0.5,5,7.4],\n",
    "                [1.35,0,0.5,5,7.4],\n",
    "                [1.4,0,0.5,5,7.4],\n",
    "                [1.45,0,0.5,5,7.4],\n",
    "                [1.5,0,0.5,6.4,7.4],\n",
    "                [1,0,0.2,1,7.4],\n",
    "                [1,0,0.25,2,7.4],\n",
    "                [1,0,0.3,3,7.4],\n",
    "                [1,0,0.35,3.5,7.4],\n",
    "                [1,0,0.4,4,7.4],\n",
    "                [1,0,0.45,4,7.4],\n",
    "                [1,0,0.5,4,7.4],\n",
    "                [1,0,0.55,4,7.4],\n",
    "                [1,0,0.6,4,7.4],\n",
    "                [1,0,0.65,3.5,7.4],\n",
    "                [1,0,0.7,3.5,7.4],\n",
    "                [1.5,0,0.05,5.5,7.4],\n",
    "                [1.5,0,0.1,5.5,7.4],\n",
    "                [1.5,0,0.15,5.5,7.4],\n",
    "                [1.5,0,0.2,5.5,7.4],\n",
    "                [1.5,0,0.25,5.5,7.4],\n",
    "                [1.5,0,0.3,5.5,7.4],\n",
    "                [1.5,0,0.35,5.5,7.4],\n",
    "                [1.5,0,0.4,5.5,7.4],\n",
    "                [1.5,0,0.45,6.4,7.4],\n",
    "                [1.5,0,0.5,6.4,7.4]\n",
    "                ])\n",
    "\n",
    "QEListHK0 = np.array([[0.55,0.5,0,5,7.4],\n",
    "                [0.6,0.5,0,5,7.4],\n",
    "                [0.65,0.5,0,5,7.4],\n",
    "                [0.7,0.5,0,5,7.4],\n",
    "                [0.75,0.5,0,5,7.4],\n",
    "                [0.8,0.5,0,5,7.4],\n",
    "                [0.85,0.5,0,5,7.4],\n",
    "                [0.9,0.5,0,5,7.4],\n",
    "                [0.95,0.5,0,5,7.4],\n",
    "                [1,0.5,0,5,7.4],\n",
    "                [1.05,0.5,0,5,7.4],\n",
    "                [1.1,0.5,0,5,7.4],\n",
    "                [1.15,0.5,0,5,7.4],\n",
    "                [1.2,0.5,0,5,7.4],\n",
    "                [1.25,0.5,0,5,7.4],\n",
    "                [1.3,0.5,0,5,7.4],\n",
    "                [1.35,0.5,0,5,7.4],\n",
    "                [1.4,0.5,0,5,7.4],\n",
    "                [1.45,0.5,0,5,7.4],\n",
    "                [1.5,0.5,0,5,7.4]\n",
    "                ])\n",
    "\n",
    "widthHHL = 0.03 # 1/Å\n",
    "minPixelHHL = 0.05 # meV\n",
    "\n",
    "widthH0L = 0.03 # 1/Å\n",
    "minPixelH0L = 0.05 # meV\n",
    "\n",
    "widthHK0 = 0.03 # 1/Å\n",
    "minPixelHK0 = 0.05 # meV\n",
    "\n",
    "for QPoint in QEListHHL:\n",
    "    dat,_ = dsHHL.cut1DE(q=QPoint[0:3],E1=QPoint[3],E2=QPoint[4],width=widthHHL,minPixel=minPixelHHL,constantBins=True)\n",
    "    dataFrames.append(dat)\n",
    "\n",
    "for QPoint in QEListH0L:\n",
    "    dat,_ = dsH0L.cut1DE(q=QPoint[0:3],E1=QPoint[3],E2=QPoint[4],width=widthH0L,minPixel=minPixelH0L,constantBins=True)\n",
    "    dataFrames.append(dat)\n",
    "\n",
    "for QPoint in QEListHK0:\n",
    "    dat,_ = dsHK0.cut1DE(q=QPoint[0:3],E1=QPoint[3],E2=QPoint[4],width=widthHK0,minPixel=minPixelHK0,constantBins=True)\n",
    "    dataFrames.append(dat)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#combiFig, combiAxis = plt.subplots()\n",
    "\n",
    "#for d in dataFrames:\n",
    "#    Intensity = d['Int']\n",
    "    # The error is calculated using the Gaussian approximation and normalized to monitor and instrument sensitivity\n",
    "#    Error = d['Int_err']\n",
    "#    E = d['Energy']\n",
    "#    combiAxis.errorbar(E,Intensity,yerr=Error,fmt='.-', label='({:.2f}, {:.2f}, {:.2f})'.format(np.mean(d['H']), np.mean(d['K']), np.mean(d['L'])))\n",
    "    \n",
    "#combiAxis.set_xlabel('E [meV]')\n",
    "#combiAxis.set_ylabel('Intensity [arb]')\n",
    "#combiAxis.legend(frameon=False)\n",
    "#combiAxis.get_figure().set_size_inches(16,12)\n",
    "#combiFig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fit the peaks and output the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (not used) Fit the peaks and output the text file for SpinW: 0 T A to Z for J3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "fitE = []\n",
    "errE = []\n",
    "fitI = []\n",
    "errI = []\n",
    "for i in range(len(dataFramesAZ)):\n",
    "    fitFigAZ,fitAxAZ = plt.subplots()\n",
    "\n",
    "    IntensityPre = dataFramesAZ[i]['Int']\n",
    "    ErrorPre = dataFramesAZ[i]['Int_err']\n",
    "    EPre = dataFramesAZ[i]['Energy']\n",
    "\n",
    "    # Drop bins with 0 counts, reset Pandas series indexing\n",
    "    Intensity = IntensityPre[IntensityPre!=0].reset_index(drop=True)\n",
    "    Error = ErrorPre[IntensityPre!=0].reset_index(drop=True)\n",
    "    E = EPre[IntensityPre!=0].reset_index(drop=True)\n",
    "\n",
    "    # The guess follows the input list from the function. Amplitude and center position is found from the maximal intensity position\n",
    "    centerId = np.argmax(Intensity) # Index of maximal positin\n",
    "    mu_guess = E[centerId]\n",
    "    A_guess = Intensity[centerId]\n",
    "    sigma_guess = 0.1 # Pure gut feel guess\n",
    "    B_guess = np.min(Intensity)\n",
    "    guess = [A_guess,mu_guess,sigma_guess,B_guess]\n",
    "\n",
    "    # Call the optimization function, which returns the optimal values (fit) and the correlation \n",
    "    # matrix (Var_mat) from which the actual error estiamte can be found\n",
    "    fit,Var_mat = curve_fit(Gaussian,E,Intensity,p0=guess,sigma=Error)\n",
    "\n",
    "    # For simplicity, it is assumed that the errors are uncorrelated and thus equal to the square root of the diagonal\n",
    "    fit_err = np.sqrt(np.diag(Var_mat))\n",
    "\n",
    "    # Create a variable against which the fit is plotted\n",
    "    X = np.linspace(np.min(E),np.max(E),101)\n",
    "    Y = Gaussian(X,*fit) # Notice: using the * operator here unpacks all of the values so that you don't have to write them by hand\n",
    "    Init = Gaussian(X,*guess)\n",
    "\n",
    "    # Plot data\n",
    "    fitAxAZ.errorbar(E,Intensity,yerr=Error,fmt='.-', label='({:.2f}, {:.2f}, {:.2f})'.format(np.mean(dataFramesAZ[i]['H']), np.mean(dataFramesAZ[i]['K']), np.mean(dataFramesAZ[i]['L'])))\n",
    "    # Plot fit\n",
    "    fitAxAZ.plot(X,Y,label='Fit')\n",
    "    fitAxAZ.plot(X,Init,label='Initial Guess')\n",
    "    fitAxAZ.set_xlabel('E [meV]')\n",
    "    fitAxAZ.set_ylabel('Intensity [Arb]')\n",
    "    fitAxAZ.legend()\n",
    "    fitE.append(fit[1])\n",
    "    errE.append(fit_err[1]) # Square root of diagonal of covariance matrix\n",
    "    fitI.append(fit[0])\n",
    "    errI.append(fit_err[0])\n",
    "    plt.show()\n",
    "    print('Q: ({:.2f}, {:.2f}, {:.2f}). E = {:.3f} +- {:.3f}'.format(np.mean(dataFramesAZ[i]['H']), np.mean(dataFramesAZ[i]['K']), np.mean(dataFramesAZ[i]['L']), fit[1], fit_err[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fitted dispersion to text file for SpinW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtFilename = '1p5K_0T_AZ_FitDisp'\n",
    "\n",
    "txtFile = 'U:/Data/MATLAB/MnF2/' + txtFilename + '.txt'\n",
    "fid = open(txtFile, 'w')\n",
    "fid.write('QH QK QL ENlim1 ENlim2 I1 EN1 s1\\n')\n",
    "for i in range(len(dataFramesAZ)):\n",
    "    d = dataFramesAZ[i]\n",
    "    txt = \"{:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}\\n\"\n",
    "    fid.write(txt.format(np.mean(d['H']), np.mean(d['K']), np.mean(d['L']), 0.5, 10, fitI[i], fitE[i], errE[i]))\n",
    "\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fit the peaks and output the text file for SpinW: 0 T Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit The Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Run multiple times for different dataframes or make it into a loop\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "fitE = []\n",
    "errE = []\n",
    "fitI = []\n",
    "errI = []\n",
    "for i in range(len(dataFrames)):\n",
    "    fitFig,fitAx = plt.subplots()\n",
    "\n",
    "    IntensityPre = dataFrames[i]['Int']\n",
    "    ErrorPre = dataFrames[i]['Int_err']\n",
    "    EPre = dataFrames[i]['Energy']\n",
    "\n",
    "    # Drop bins with 0 counts, reset Pandas series indexing\n",
    "    Intensity = IntensityPre[IntensityPre!=0].reset_index(drop=True)\n",
    "    Error = ErrorPre[IntensityPre!=0].reset_index(drop=True)\n",
    "    E = EPre[IntensityPre!=0].reset_index(drop=True)\n",
    "\n",
    "    # The guess follows the input list from the function. Amplitude and center position is found from the maximal intensity position\n",
    "    centerId = np.argmax(Intensity) # Index of maximal positin\n",
    "    mu_guess = E[centerId]\n",
    "    A_guess = Intensity[centerId]\n",
    "    sigma_guess = 0.25 # Pure gut feel guess\n",
    "    B_guess = np.min(Intensity)\n",
    "    guess = [A_guess,mu_guess,sigma_guess,B_guess]\n",
    "\n",
    "    # Call the optimization function, which returns the optimal values (fit) and the correlation \n",
    "    # matrix (Var_mat) from which the actual error estiamte can be found\n",
    "    fit,Var_mat = curve_fit(Gaussian,E,Intensity,p0=guess,sigma=Error)\n",
    "\n",
    "    # For simplicity, it is assumed that the errors are uncorrelated and thus equal to the square root of the diagonal\n",
    "    fit_err = np.sqrt(np.diag(Var_mat))\n",
    "\n",
    "    # Create a variable against which the fit is plotted\n",
    "    X = np.linspace(np.min(E),np.max(E),101)\n",
    "    Y = Gaussian(X,*fit) # Notice: using the * operator here unpacks all of the values so that you don't have to write them by hand\n",
    "    Init = Gaussian(X,*guess)\n",
    "\n",
    "    # Plot data\n",
    "    fitAx.errorbar(E,Intensity,yerr=Error,fmt='.-', label='({:.2f}, {:.2f}, {:.2f})'.format(np.mean(dataFrames[i]['H']), np.mean(dataFrames[i]['K']), np.mean(dataFrames[i]['L'])))\n",
    "    # Plot fit\n",
    "    fitAx.plot(X,Y,label='Fit')\n",
    "    fitAx.plot(X,Init,label='Initial Guess')\n",
    "    fitAx.set_xlabel('E [meV]')\n",
    "    fitAx.set_ylabel('Intensity [Arb]')\n",
    "    fitAx.legend()\n",
    "    #if i==4 or i==73: # Use Johnson 1959 AFMR result as discussed in Hagiwara 1996\n",
    "    #    fitE.append(1.081) # Unit conversion: https://www.ill.eu/fileadmin/user_upload/ILL/3_Users/Support_labs_infrastructure/Software-tools/DIF_tools/neutrons.html\n",
    "    #    errE.append(0.006)\n",
    "    #else:\n",
    "    #    fitE.append(fit[1])\n",
    "    #    errE.append(fit_err[1]) # Square root of diagonal of covariance matrix\n",
    "    fitE.append(fit[1])\n",
    "    errE.append(fit_err[1]) # Square root of diagonal of covariance matrix\n",
    "    fitI.append(fit[0])\n",
    "    errI.append(fit_err[0])\n",
    "    plt.show()\n",
    "    print('Q: ({:.2f}, {:.2f}, {:.2f}). E = {:.3f} +- {:.3f}'.format(np.mean(dataFrames[i]['H']), np.mean(dataFrames[i]['K']), np.mean(dataFrames[i]['L']), fit[1], fit_err[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted dispersion to text file for SpinW\n",
    "xtFilename = '1p5K_0T_FitDisp'\n",
    "\n",
    "txtFile = 'U:/Data/MATLAB/MnF2/' + txtFilename + '.txt'\n",
    "fid = open(txtFile, 'w')\n",
    "fid.write('QH QK QL ENlim1 ENlim2 I1 EN1 s1\\n')\n",
    "for i in range(len(dataFrames)):\n",
    "    d = dataFrames[i]\n",
    "    txt = \"{:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}\\n\"\n",
    "    fid.write(txt.format(np.mean(d['H']), np.mean(d['K']), np.mean(d['L']), 0.5, 10, fitI[i], fitE[i], errE[i]))\n",
    "\n",
    "fid.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
